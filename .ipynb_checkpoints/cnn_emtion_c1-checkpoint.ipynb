{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56e5223e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pyeeg as pe\n",
    "import pickle as pickle\n",
    "import pandas as pd\n",
    "import math\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "import tensorflow as tf\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b64516df",
   "metadata": {},
   "outputs": [],
   "source": [
    "channel = [1] #14 Channels chosen to fit Emotiv Epoch+\n",
    "band = [4,8,12,16,25,45] #5 bands\n",
    "window_size = 256 #Averaging band power of 2 sec\n",
    "step_size = 16 #Each 0.125 sec update once\n",
    "sample_rate = 128 #Sampling rate of 128 Hz\n",
    "subjectList = ['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12', '13', '14', '15', '16', '17',\n",
    "               '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32']\n",
    "# List of subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f4dbd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# loading training and testing dataset\n",
    "\n",
    "with open('data_training.npy', 'rb') as fileTrain:\n",
    "    X  = np.load(fileTrain)\n",
    "    \n",
    "with open('label_training.npy', 'rb') as fileTrainL:\n",
    "    Y  = np.load(fileTrainL)\n",
    "    \n",
    "\n",
    "X = normalize(X)  # 归一化\n",
    "Z = np.ravel(Y[:, [1]])  # 扁平化\n",
    "\n",
    "Valence_Train = np.ravel(Y[:, [0]])\n",
    "Arousal_Train = np.ravel(Y[:, [1]])\n",
    "Domain_Train = np.ravel(Y[:, [2]])\n",
    "Like_Train = np.ravel(Y[:, [3]])\n",
    "\n",
    "with open( 'data_validation.npy', 'rb') as fileTrain:\n",
    "    M = np.load(fileTrain)\n",
    "\n",
    "with open('label_validation.npy', 'rb') as fileTrainL:\n",
    "    N = np.load(fileTrainL)\n",
    "\n",
    "M = normalize(M)\n",
    "L = np.ravel(N[:, [1]])  # arousa标签\n",
    "\n",
    "Valence_Test = np.ravel(N[:, [0]])\n",
    "Arousal_Test = np.ravel(N[:, [1]])\n",
    "Domain_Test = np.ravel(N[:, [2]])\n",
    "Like_Test = np.ravel(N[:, [3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "23fb0687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "2\n",
      "tf.Tensor(7.6, shape=(), dtype=float64)\n",
      "tf.Tensor(7.6, shape=(), dtype=float64)\n",
      "tf.Tensor(9, shape=(), dtype=int32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor([0. 0. 0. 0. 0. 0. 0. 1.], shape=(8,), dtype=float32)\n",
      "tf.Tensor([14640     5], shape=(2,), dtype=int32) (14640, 5)\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "def preprocess(y):  # 此函数可用于二分类任务，原始数组中小于等于5的元素被转换成0，大于5的元素被转换成1\n",
    "                    # 将数值类的标签转换为二进制的类别标签\n",
    "    result = []\n",
    "    for i in range(len(y)):\n",
    "        if y[i] <= 5:\n",
    "            result.append(0)\n",
    "        else:\n",
    "            result.append(1) \n",
    "    result = np.array(result)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "# Pull out columns for X (data to train with) and Y (value to predict)拉出X（要训练的数据）和Y（要预测的值）的列\n",
    "X_training = X[0:468480:32]\n",
    "Y_training = Z[0:468480:32]\n",
    "\n",
    "# Pull out columns for X (data to train with) and Y (value to predict)拉出X（要训练的数据）和Y（要预测的值）的列\n",
    "X_testing = M[0:78080:32]\n",
    "Y_testing = L[0:78080:32]\n",
    "\n",
    "# DO Scale both the training inputs and outputs对训练的输入输出进行衡量\n",
    "X_scaled_training = pd.DataFrame(data=X_training).values\n",
    "Y_scaled_training = pd.DataFrame(data=Y_training).values\n",
    "\n",
    "# It's very important that the training and test data are scaled with the same scaler.使用同一个定标器对训练和测试数据进行缩放是非常重要的。\n",
    "X_scaled_testing = pd.DataFrame(data=X_testing).values\n",
    "Y_scaled_testing = pd.DataFrame(data=Y_testing).values\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_scaled_training  = tf.convert_to_tensor(X_scaled_training, dtype=tf.float32)\n",
    "\n",
    "print(type(X_scaled_training))\n",
    "print('2')\n",
    "# 训练集标签处理\n",
    "Y_scaled_training = tf.reshape(Y_scaled_training, [-1])\n",
    "# print(max(Y_scaled_training))\n",
    "# print(min(Y_scaled_training))\n",
    "print(Y_scaled_training[0])\n",
    "Y_scaled_training = preprocess(Y_scaled_training)\n",
    "print(Y_scaled_training[0])\n",
    "Y_scaled_training = tf.cast(Y_scaled_training, dtype=tf.int32)\n",
    "print(max(Y_scaled_training))\n",
    "print(min(Y_scaled_training))\n",
    "Y_scaled_training = tf.one_hot(Y_scaled_training, 8)\n",
    "print(Y_scaled_training[0])\n",
    "\n",
    "# 测试机标签处理\n",
    "Y_scaled_testing = tf.reshape(Y_scaled_testing, [-1])\n",
    "Y_scaled_testing = preprocess(Y_scaled_testing)\n",
    "Y_scaled_testing = tf.cast(Y_scaled_testing, dtype=tf.int32)\n",
    "Y_scaled_testing = tf.one_hot(Y_scaled_testing, 8)\n",
    "\n",
    "print(tf.shape(X_scaled_training), np.array(X_scaled_training).shape)\n",
    "print(type(X_scaled_training))\n",
    "print(type(Y_scaled_training))\n",
    "print('3')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1e35124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "batch_size = 256\n",
    "num_classes = 8\n",
    "epochs = 200\n",
    "input_shape=(X_scaled_training.shape[1], 1)\n",
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af0d8ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Convolution1D, ZeroPadding1D, MaxPooling1D, BatchNormalization, Activation, Dropout, Flatten, Dense\n",
    "from keras.regularizers import l2\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, BatchNormalization, MaxPooling1D, Dense, Flatten, Dropout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4955d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 5, 64)             256       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 5, 64)            256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 5, 128)            24704     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 5, 128)           512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 3, 256)            98560     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 3, 256)           1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 3, 256)            196864    \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 3, 256)           1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, 2, 512)            393728    \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 2, 512)           2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv1d_5 (Conv1D)           (None, 2, 512)            786944    \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 2, 512)           2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               131200    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 8)                 1032      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,640,200\n",
      "Trainable params: 1,636,744\n",
      "Non-trainable params: 3,456\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# input_shape = (x_train.shape[1], x_train.shape[2])\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(64, kernel_size=3, padding='same', activation='relu', input_shape=input_shape))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv1D(128, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv1D(256, kernel_size=3, padding='same', activation='relu', strides=2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv1D(256, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv1D(512, kernel_size=3, padding='same', activation='relu', strides=2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv1D(512, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='tanh'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6146d796",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "241d8125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Conv1D, BatchNormalization, Flatten, Dense, Dropout\n",
    "# from tensorflow.keras.utils import plot_model\n",
    "\n",
    "# # Create the model\n",
    "# model = Sequential()\n",
    "# model.add(Conv1D(64, kernel_size=3, activation='relu', input_shape=(5, 1)))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Conv1D(128, kernel_size=3, activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Conv1D(256, kernel_size=3, activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Conv1D(256, kernel_size=3, activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Conv1D(512, kernel_size=3, activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Conv1D(512, kernel_size=3, activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(128, activation='relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# # Visualize the model structure\n",
    "# plot_model(model, to_file='model.png', show_shapes=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c2d127b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3be32509",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "You must compile your model before training/testing. Use `model.compile(optimizer, loss)`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 调用tf.keras封装的训练接口，开始训练\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_scaled_training\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mY_scaled_training\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_scaled_testing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_scaled_testing\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/sleep_emotion/lib/python3.8/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/envs/sleep_emotion/lib/python3.8/site-packages/keras/engine/training.py:3685\u001b[0m, in \u001b[0;36mModel._assert_compile_was_called\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3679\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_assert_compile_was_called\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   3680\u001b[0m     \u001b[38;5;66;03m# Checks whether `compile` has been called. If it has been called,\u001b[39;00m\n\u001b[1;32m   3681\u001b[0m     \u001b[38;5;66;03m# then the optimizer is set. This is different from whether the\u001b[39;00m\n\u001b[1;32m   3682\u001b[0m     \u001b[38;5;66;03m# model is compiled\u001b[39;00m\n\u001b[1;32m   3683\u001b[0m     \u001b[38;5;66;03m# (i.e. whether the model is built and its inputs/outputs are set).\u001b[39;00m\n\u001b[1;32m   3684\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_compiled:\n\u001b[0;32m-> 3685\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   3686\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou must compile your model before \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3687\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining/testing. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3688\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse `model.compile(optimizer, loss)`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3689\u001b[0m         )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: You must compile your model before training/testing. Use `model.compile(optimizer, loss)`."
     ]
    }
   ],
   "source": [
    "# 调用tf.keras封装的训练接口，开始训练\n",
    "history = model.fit(x=X_scaled_training, y=Y_scaled_training, epochs=100, validation_data=(X_scaled_testing, Y_scaled_testing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "acb4e29e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# 画图\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mhistory\u001b[49m\u001b[38;5;241m.\u001b[39mhistory\u001b[38;5;241m.\u001b[39mkeys()\n\u001b[1;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(history\u001b[38;5;241m.\u001b[39mepoch, history\u001b[38;5;241m.\u001b[39mhistory\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m), label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(history\u001b[38;5;241m.\u001b[39mepoch, history\u001b[38;5;241m.\u001b[39mhistory\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m), label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 画图\n",
    "history.history.keys()\n",
    "plt.plot(history.epoch, history.history.get('accuracy'), label='accuracy')\n",
    "plt.plot(history.epoch, history.history.get('val_accuracy'), label='val_accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "69a44872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for loss\n",
    "\n",
    "plt.plot(history.epoch, history.history.get('loss'), label='loss')\n",
    "plt.plot(history.epoch, history.history.get('val_loss'), label='val_loss')\n",
    "\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['loss', 'val_loss'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8f1a0966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the library\n",
    "from tensorflow.keras.models import load_model\n",
    "# Save the model using TensorFlow SavedModel format\n",
    "model.save('CNN_EMTION_C1_6emo.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e21142",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:sleep_emotion] *",
   "language": "python",
   "name": "conda-env-sleep_emotion-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
