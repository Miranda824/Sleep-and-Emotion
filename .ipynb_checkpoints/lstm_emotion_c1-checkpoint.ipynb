{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a9f1852",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pyeeg as pe\n",
    "import pickle as pickle\n",
    "import pandas as pd\n",
    "import math\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "import tensorflow as tf\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57230d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "channel = [1] #14 Channels chosen to fit Emotiv Epoch+\n",
    "band = [4,8,12,16,25,45] #5 bands\n",
    "window_size = 256 #Averaging band power of 2 sec\n",
    "step_size = 16 #Each 0.125 sec update once\n",
    "sample_rate = 128 #Sampling rate of 128 Hz\n",
    "subjectList = ['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12', '13', '14', '15', '16', '17',\n",
    "               '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32']\n",
    "# List of subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f00dbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# loading training and testing dataset\n",
    "\n",
    "with open('data_training.npy', 'rb') as fileTrain:\n",
    "    X  = np.load(fileTrain)\n",
    "    \n",
    "with open('label_training.npy', 'rb') as fileTrainL:\n",
    "    Y  = np.load(fileTrainL)\n",
    "    \n",
    "\n",
    "X = normalize(X)  # 归一化\n",
    "Z = np.ravel(Y[:, [1]])  # 扁平化\n",
    "\n",
    "Valence_Train = np.ravel(Y[:, [0]])\n",
    "Arousal_Train = np.ravel(Y[:, [1]])\n",
    "Domain_Train = np.ravel(Y[:, [2]])\n",
    "Like_Train = np.ravel(Y[:, [3]])\n",
    "\n",
    "with open( 'data_validation.npy', 'rb') as fileTrain:\n",
    "    M = np.load(fileTrain)\n",
    "\n",
    "with open('label_validation.npy', 'rb') as fileTrainL:\n",
    "    N = np.load(fileTrainL)\n",
    "\n",
    "M = normalize(M)\n",
    "L = np.ravel(N[:, [1]])  # arousa标签\n",
    "\n",
    "Valence_Test = np.ravel(N[:, [0]])\n",
    "Arousal_Test = np.ravel(N[:, [1]])\n",
    "Domain_Test = np.ravel(N[:, [2]])\n",
    "Like_Test = np.ravel(N[:, [3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d146d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "2\n",
      "tf.Tensor([14640     5], shape=(2,), dtype=int32) (14640, 5)\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "def preprocess(y):\n",
    "    result = []\n",
    "    for i in range(len(y)):\n",
    "        if y[i] <= 5:\n",
    "            result.append(0)\n",
    "        else:\n",
    "            result.append(1)\n",
    "    result = np.array(result)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "# Pull out columns for X (data to train with) and Y (value to predict)拉出X（要训练的数据）和Y（要预测的值）的列\n",
    "X_training = X[0:468480:32]\n",
    "Y_training = Z[0:468480:32]\n",
    "\n",
    "# Pull out columns for X (data to train with) and Y (value to predict)拉出X（要训练的数据）和Y（要预测的值）的列\n",
    "X_testing = M[0:78080:32]\n",
    "Y_testing = L[0:78080:32]\n",
    "\n",
    "# DO Scale both the training inputs and outputs对训练的输入输出进行衡量\n",
    "X_scaled_training = pd.DataFrame(data=X_training).values\n",
    "Y_scaled_training = pd.DataFrame(data=Y_training).values\n",
    "\n",
    "# It's very important that the training and test data are scaled with the same scaler.使用同一个定标器对训练和测试数据进行缩放是非常重要的。\n",
    "X_scaled_testing = pd.DataFrame(data=X_testing).values\n",
    "Y_scaled_testing = pd.DataFrame(data=Y_testing).values\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_scaled_training  = tf.convert_to_tensor(X_scaled_training, dtype=tf.float32)\n",
    "\n",
    "print(type(X_scaled_training))\n",
    "print('2')\n",
    "# 训练集标签处理\n",
    "Y_scaled_training = tf.reshape(Y_scaled_training, [-1])\n",
    "Y_scaled_training = preprocess(Y_scaled_training)\n",
    "Y_scaled_training = tf.cast(Y_scaled_training, dtype=tf.int32)\n",
    "Y_scaled_training = tf.one_hot(Y_scaled_training, 10)\n",
    "\n",
    "# 测试机标签处理\n",
    "Y_scaled_testing = tf.reshape(Y_scaled_testing, [-1])\n",
    "Y_scaled_testing = preprocess(Y_scaled_testing)\n",
    "Y_scaled_testing = tf.cast(Y_scaled_testing, dtype=tf.int32)\n",
    "Y_scaled_testing = tf.one_hot(Y_scaled_testing, 10)\n",
    "\n",
    "print(tf.shape(X_scaled_training), np.array(X_scaled_training).shape)\n",
    "print(type(X_scaled_training))\n",
    "print(type(Y_scaled_training))\n",
    "print('3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bad51e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "batch_size = 256\n",
    "num_classes = 10\n",
    "epochs = 200\n",
    "input_shape=(X_scaled_training.shape[1], 1)\n",
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8854d5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Convolution1D, ZeroPadding1D, MaxPooling1D, BatchNormalization, Activation, Dropout, Flatten, Dense\n",
    "from keras.regularizers import l2\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, BatchNormalization, MaxPooling1D, Dense, Flatten, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1fe78679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 5)                 30        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 512)               3072      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1024)              525312    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 512)               524800    \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,107,944\n",
      "Trainable params: 2,107,944\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(5),  # 输入层\n",
    "    tf.keras.layers.Dense(512, activation=tf.nn.relu),  # 第一层\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(1024, activation=tf.nn.relu),  # 第二层\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(1024, activation=tf.nn.relu),  # 第三层\n",
    "    tf.keras.layers.Dense(512, activation=tf.nn.relu),  # 第四层\n",
    "    # 输出层，2分类问题，激活函数为softmax\n",
    "    tf.keras.layers.Dense(num_classes, activation=tf.nn.softmax)  # 输出层\n",
    "])\n",
    "\n",
    "# 输出一下模型的结构\n",
    "model.build((None, 5))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9e0614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "458/458 [==============================] - 11s 21ms/step - loss: 0.7054 - accuracy: 0.5553 - val_loss: 0.6828 - val_accuracy: 0.5740\n",
      "Epoch 2/100\n",
      "458/458 [==============================] - 9s 19ms/step - loss: 0.6852 - accuracy: 0.5693 - val_loss: 0.6836 - val_accuracy: 0.5740\n",
      "Epoch 3/100\n",
      "458/458 [==============================] - 9s 19ms/step - loss: 0.6833 - accuracy: 0.5727 - val_loss: 0.6828 - val_accuracy: 0.5740\n",
      "Epoch 4/100\n",
      "458/458 [==============================] - 9s 19ms/step - loss: 0.6832 - accuracy: 0.5751 - val_loss: 0.6820 - val_accuracy: 0.5740\n",
      "Epoch 5/100\n",
      "458/458 [==============================] - 9s 19ms/step - loss: 0.6821 - accuracy: 0.5747 - val_loss: 0.6825 - val_accuracy: 0.5748\n",
      "Epoch 6/100\n",
      "458/458 [==============================] - ETA: 0s - loss: 0.6816 - accuracy: 0.5745"
     ]
    }
   ],
   "source": [
    "# 配置优化器、损失函数以及监控指标\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss=tf.keras.losses.categorical_crossentropy,\n",
    "              metrics=['accuracy'])\n",
    "# 调用tf.keras封装的训练接口，开始训练\n",
    "history = model.fit(x=X_scaled_training, y=Y_scaled_training, epochs=100, validation_data=(X_scaled_testing, Y_scaled_testing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5356c86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 画图\n",
    "history.history.keys()\n",
    "plt.plot(history.epoch, history.history.get('accuracy'), label='accuracy')\n",
    "plt.plot(history.epoch, history.history.get('val_accuracy'), label='val_accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d06284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for loss\n",
    "\n",
    "plt.plot(history.epoch, history.history.get('loss'), label='loss')\n",
    "plt.plot(history.epoch, history.history.get('val_loss'), label='val_loss')\n",
    "\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['loss', 'val_loss'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1833dde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the library\n",
    "from tensorflow.keras.models import load_model\n",
    "# Save the model using TensorFlow SavedModel format\n",
    "model.save('LSTM_EMOTION_C1.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:sleep_emotion] *",
   "language": "python",
   "name": "conda-env-sleep_emotion-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
